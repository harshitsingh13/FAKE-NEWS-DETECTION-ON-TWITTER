# -*- coding: utf-8 -*-
"""Cloud_of_Words.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DSvM5PXn45bxcgm4nyRiWq8oUbFF0Ikq
"""

import json
import csv
from collections import Counter
import operator
import numpy as np
import matplotlib.pyplot as plt
import nltk
import string
import wordcloud
import pandas as pd

nltk.download('punkt')
nltk.download('stopwords')

'''
f=open('ponguru_data.csv', 'r', encoding='utf-8')
l=0
for x in f :
    l+=1
    if x!=''  and l!=1:
        s=x[20:]
        s=s.split(" ")
        text=""
        for j in s :
            text+=j
            text+=" "
        twitter_data.append(text)
'''
twitter_data=[]
f=open('rajinikanth_tweets.csv', 'r')
for x in f :
    if x!=[] :
        list_of_words=x.split(',')
        if list_of_words!=['\n'] :
            twitter_data.append(list_of_words[2])

def worddc(x):
    tokens = []
    for i in x:
        tokens += nltk.tokenize.word_tokenize(i)
    tokens = [i.lower() for i in tokens]
    k=string.punctuation
    #k=k.replace('#','')
    #k=k.replace('@','')
    obj=str.maketrans('', '',k)
    tokens = [i.translate(obj) for i in tokens]
    k='0123456789'
    obj=str.maketrans('', '',k)
    tokens = [i.translate(obj) for i in tokens]
    
    
    stop_words = set(nltk.corpus.stopwords.words("english"))
    tokens = [i for i in tokens if i not in stop_words]
    tokens = [i for i in tokens if len(i)>2]
    c = Counter(tokens)
    word_cloud_2={}
    for i in dict(c):
        if(i!='https' and i!='com' and i!='brt' and i!='http' and i!='tcoa6lwdt1i5s'):
            if(i[:3]!='www' and (i[0] in string.ascii_lowercase)):
                if i=='bthank' :
                     word_cloud_2['thank']=dict(c)[i]
                else :
                    word_cloud_2[i]=dict(c)[i]
    
    word_cloud_2_list=sorted(word_cloud_2.items(),key=operator.itemgetter(1))
    word_cloud_2_list=word_cloud_2_list[::-1]
    print(word_cloud_2_list[:10])
    
    wc = wordcloud.WordCloud(background_color="rgba(255, 255, 255, 0)", mode="RGBA",width=2000,height=2000,relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(dict(word_cloud_2_list))
    plt.figure( figsize=(20,10))
    plt.axis("off")
    plt.imshow(wc)

for i in range(len(twitter_data)):
    p=twitter_data[i].find('\\x')
    if(p!=-1):
        twitter_data[i]=twitter_data[i][:p]
print(twitter_data)

worddc(twitter_data)

